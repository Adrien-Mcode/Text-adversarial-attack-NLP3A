# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vttOtNmo_C4HPRaqfOwmKO9JkqgmdNEI
"""

#  NLP Project : Detecting adversarial attacks

# Implementation of the model

# In this part, we implement the entire model. It needs to be run so that we can print the ROC graphs.


#packages importation
!pip install matplotlib
!pip install numpy
!pip install sklearn
!pip install scipy
!pip install tensorflow
!pip install pandas
!pip install datasets
!pip install evaluate
!pip install scienceplots

#general 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch

#for models
import tensorflow as tf
!pip install transformers
import transformers as tr
import datasets as dt
!pip install sentence_transformers
import sklearn.covariance as Covariance
import sklearn.decomposition as Decomposition
from sentence_transformers import SentenceTransformer
from scipy.stats import multivariate_normal
from scipy.linalg import sqrtm
from tqdm.auto import tqdm
import evaluate as ev


#model
def full_model_evaluation(dataset, text_col, label_col) :
    text_train, text_test, label_train, label_test = sklearn.model_selection.train_test_split(dataset[text_col], dataset[label_col], test_size=0.33, random_state=42)

def get_dataset(dataset_name, model, attack_name):
    filename = model + '-' + dataset_name + "_" + attack_name + ".csv"
    dataframe = pd.read_csv(filename)
    return dataframe

def text_cleaner(text):
    return text.replace("[","").replace("]","")

def make_train_test(dataset_name, model, attack_name, number_attack_sample = 1000):
    dataset = get_dataset(dataset_name, model, attack_name)
    #keep only the columns that will be useful, ie "original text", "perturbed text" and "ground_truth_output"
    dataset = dataset[["original_text", "perturbed_text", "ground_truth_output", "result_type"]]
    
    #clean the text columns : 
    dataset["original_text"] = dataset["original_text"].map(text_cleaner)
    dataset["perturbed_text"] = dataset["perturbed_text"].map(text_cleaner)
    
    #Now shuffle the dataset with a full sampling without replacement such that any order would be destroyed : 
    dataset = dataset.sample(frac=1).reset_index(drop = True)
    
    #we will keep "number_attack_sample" adversarial example :
    adversarial_sample = dataset.loc[:number_attack_sample-1].reset_index(drop = True)
    normal_sample = dataset.loc[number_attack_sample:].reset_index(drop = True)
    
    #we will retain only the adversarial samples that were successful : 
    adversarial_sample = adversarial_sample.loc[adversarial_sample["result_type"] == "Successful"]
    #in adversarial sample we simply need the text : 
    adversarial_sample = adversarial_sample.drop(["original_text","ground_truth_output", "result_type"], axis = 1)
    
    #for non adversarial we need to separate one time more : one part will be for training and another one for testing.
    #We will keep for testing as much normal example as we have adversarial examples : 
    normal_test_sample = normal_sample.loc[:number_attack_sample-1].reset_index(drop = True)
    train_sample = normal_sample.loc[number_attack_sample:].reset_index(drop = True)
    
    normal_test_sample = normal_test_sample.drop(["perturbed_text","ground_truth_output", "result_type"], axis = 1)
    train_sample = train_sample.drop(["perturbed_text", "result_type"], axis = 1)
    
    train_sample.columns = ["text","label"]
        
    #now fuse the test set, with a new "label" column that will contain if it's an attack or not : 
    adversarial_sample.columns = ["text"]
    normal_test_sample.columns = ["text"]
    
    test_sample = pd.concat([adversarial_sample, normal_test_sample], axis = 0)
    test_sample["label"] = np.concatenate([np.ones(adversarial_sample.shape[0]),np.zeros(number_attack_sample)], axis = 0)
    
    #shuffle : 
    test_sample = test_sample.sample(frac=1).reset_index(drop = True)
    
    return {"train" : train_sample, "test": test_sample}

def get_embeddings(model, data):
    embedder = SentenceTransformer(model)
    
    #if dict, return a dict of embeddings with same keys : 
    if isinstance(data, dict):
        embeddings_dict = {}
        for key in data.keys() : 
            embeddings_dict[key] = embedder.encode(data[key]["text"])
        return embeddings_dict
    
    #if not, a dataframe is expected and only the embeddings: 
    else :
        embeddings = embedder.encode(data["text"])
        return embeddings

def gaussian_logdens(mean,cov):
    inv_cov = np.linalg.inv(cov)
    def dens(x):
        centered_x = x-mean
        return np.dot(np.dot(centered_x, inv_cov),centered_x)
    return dens

def make_detector(train_embeddings, train_label, estimation_type = "MLE", kernel = "rbf", calculated_density = "cond"):
    progress_bar = tqdm(range(1,3) , desc = f"Progression :")
    progress_bar.set_postfix({'Etape en cours' : 'PCA'})
    #PCA : 
    #Instantiate and use Kernel PCA : 
    PCA_kernel = Decomposition.KernelPCA(n_components = 100, kernel = kernel)
    embeddings_PCA = PCA_kernel.fit_transform(train_embeddings)

    #separation of class and then estimation : 
    #dict to keep the different double index label and mean / cov :
    class_estim = {}
    progress_bar.update(1)
    progress_bar.set_postfix({'Etape en cours' : 'Estimation'})
    for label in pd.unique(train_label):
        class_estim[label] = {}
        
        #keep only homogeneous in term of label data :
        mask_class = train_label == label
        class_homogenous_data = embeddings_PCA[mask_class]
        
        #Now the MLE estimation after PCA : 
        if estimation_type == "RDE" :
            #MCD estimation with scikit learn : 
            MCD_cov = Covariance.MinCovDet()
            MCD_cov.fit(class_homogenous_data)

            class_estim[label]["mean"] = MCD_cov.location_
            class_estim[label]["covariance"] = MCD_cov.covariance_
            
        else :
            #mean estimation
            class_estim[label]["mean"] = np.sum(class_homogenous_data, axis=0)/np.shape(class_homogenous_data)[0]
            
            #covariance estimation : shape class_estim[label]["mean"].shape[0] x class_estim[label]["mean"].shape[0]
            #then loop over lines :
            cov_shape = (class_estim[label]["mean"].shape[0],class_estim[label]["mean"].shape[0])
            class_estim[label]["covariance"] = np.zeros(cov_shape)
            for line in class_homogenous_data : 
                class_estim[label]["covariance"] += np.reshape(line,(line.shape[0],1))@np.reshape(line,(1,line.shape[0]))
    
        #We have all the matrix and mean needed, let's calculate the density : 
        class_estim[label]['density'] = gaussian_logdens(class_estim[label]["mean"], class_estim[label]["covariance"])
        if calculated_density == "join" :
            class_estim[label]['prevalence'] = np.sum(mask_class)/embeddings_PCA.shape[0]
            
    progress_bar.update(1)
    progress_bar.set_postfix({'Etape en cours' : 'CrÃ©ation fonction finale'})
    #Now that we have all that, we can def the model that take as entry text and output classification :
    def attack_detector(embedded_text):
        #make PCA on the embeddings : 
        reduced_embeddings = PCA_kernel.transform(embedded_text)
        if calculated_density == "join" : 
            density = np.zeros(reduced_embeddings.shape[0])
            threshold = 0
            for label in pd.unique(train_label):
                density += class_estim[label]['prevalence']*class_estim[label]['density'](reduced_embeddings)
            return list(density)
        else :
            result = []
            dic_classification = {"density":[],"label":[]}
            for lines in reduced_embeddings:
                prec_dens = 0
                for label in pd.unique(train_label):
                    new_dens = class_estim[label]['density'](lines)
                    if new_dens > prec_dens :
                        prec_dens = new_dens
                        max_label = label
                dic_classification["density"].append(prec_dens)
                dic_classification["label"].append(max_label)
            return dic_classification["density"]
    
    progress_bar.update(1)
    progress_bar.set_postfix({'Etape en cours' : 'Fin'})
    return attack_detector

def return_metrics(result, label, fpr_threshold):
    false_pos_r, true_pos_r, threshold = roc_curve(label, result)
    auc = roc_auc_score(label, result)
    
    #for f1-score we will need to have a label-list : 
    #First get the mask : 
    mask_threshold = (false_pos_r <= fpr_threshold)
    
    #Then the maximum true positive rate for this threshold :
    tpr_at_fpr = np.max(true_pos_r * mask_threshold)
    
    #the cutoff we need for prediction : 
    roc_cutoff = np.sort(np.unique(mask_threshold*fpr_threshold))[1]
    
    #prediction with this cutoff:
    pred = [score > roc_cutoff for score in result]
    
    f1 = f1_score(label, pred)
    
    return {"auc" : auc, "f1" : f1, "tpr" : tpr_at_fpr}